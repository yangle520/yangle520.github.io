---
layout: post
title:  主流的开源模型体系
date:   2024-12-06
categories: 学习
tag: 网址
author: YangLe
---



## 结构方面

主流的开源模型体系分为三种：

1. Perfix Decoder
   - 输入部分使用双向注意力，输出部分使用单向注意力
   - 代表模型：GLM、ChatGLM、ChatGLM2、U-PaLM
   - 桐城使用自回归方式进行训练
2. Causal Decoder
   - 输入部分使用单向注意力，输出部分使用单向注意力
   - 代表模型：GPT系列、LLaMA-7B、LLaMa衍生物
   - 用于文本生成任务
   - 通常使用自回归方式进行训练
3. Encoder Decoder
   - 输入(编码器)使用双向注意力，输出(解码器)使用单向注意力
   - 代表模型：Transformer、T5、Flan-T5、BART
   - 常用于机器翻译、文本摘要任务
   - 通常使用teacher forcing策略进行训练



## 谱系方面

1. GPT系列
   - 全称：Generative Pre-trained Transformer
   - 由 OepnAI 发布，包括 GPT-3.5、GPT-J、GPT-4、GPT-4o 等
   - 特点：具有强大的文本生成能力，能够支持自然对话
2. LLaMa系列
   - 全称：Large Language Model Meta AI
   - 由 Meta 发布，包括 LLaMA，LLaMA2 系列不同参数数量的 Base/Chat 等模型
   - 特点：基于 Transformer 架构，使用高质量数据集，Pre-normalization 预归一化，SwiGLU 激活函数，Rotary Embeddings 旋转位置编码【GPTNeo】等手段来提高模型效果
3. Baichuan系列
   - 由百川智能发布，包括 Baichuan、Baichuan2 系列不同参数的 Base/Chat 等模型
   - 中文大模型
4. Qwen系列
   - 由阿里发布，包括 Qwen、Qwen1.5、Qwen2 系列不同参数量的 Base/Instruct 等模型
5. DeepSeek系列
   - 由深度求索发布，包括 DeepSeek-VL、DeepSeek-V2 等模型
   - 多模态大模型



https://github.com/HqWu-HITCS/Awesome-Chinese-LLM?tab=readme-ov-file